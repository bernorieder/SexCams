{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics per day\n",
    "- this is code for reading multiple frontpage files and calculating metrics per timestamp (here-daily)\n",
    "- code is based on the example from \"basic_file_read\" by Bernhard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below choose which directory to work with (all files or test files)\n",
    "#path = 'homepage_csvs/test.myfreecams/' #upload test files of the platform being tested at the moment to this folder\n",
    "#path = 'homepage_csvs/chaturbate/'\n",
    "path = 'homepage_csvs/myfreecams/'\n",
    "#path = 'homepage_csvs/bongacams/'\n",
    "#path = 'homepage_csvs/livejasmin/'\n",
    "#path = 'homepage_csvs/streamate/'\n",
    "#path = 'homepage_csvs/ebonycams/'\n",
    "\n",
    "#DEPENDING ON THE PLATFORM, MAKE SURE TO ALSO DEAL WITH FILE NAMES LATER!\n",
    "\n",
    "# get all filenames from the directory\n",
    "csv_files = glob.glob(path + '*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "daily_dict = {} #create an empty dictionary to store all metrics for daily calculations\n",
    "daily_tags = {} #create an empty dictionary to store a list of all hashtags per day\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# iterate over all files to create an array of lists with all metrics for each day\n",
    "for filename in sorted(csv_files):\n",
    "\n",
    "    # extract date from filename\n",
    "    #print(filename)\n",
    "    fileparts = filename.split('_')\n",
    "    smaller_parts = fileparts[1].split('/')\n",
    "    platform_split = smaller_parts[2].split('2')\n",
    "    platform = platform_split[0]\n",
    "    #print(platform)\n",
    "    \n",
    "    if platform == \"myfreecams\":\n",
    "        myfreecams_split = smaller_parts[2].split('myfreecams')\n",
    "        date = myfreecams_split[1]\n",
    "        #print(date)\n",
    "    else:\n",
    "        date = fileparts[2]\n",
    "        #print(date)\n",
    "\n",
    "\n",
    "    print(str(counter) + ' ' + date + ' ' + platform)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "    if date not in daily_dict: #add the date to a dictionary with keys for each date\n",
    "        daily_dict[date] = {\"perf_counts\":[], \"view_sums\":[], \"show_length_sums\":[], \"female_counts\":[], \"male_counts\":[], \"trans_counts\":[], \"couple_counts\":[], \n",
    "                            \"vibrator_counts\":[], \"new_counts\":[], \"private_counts\":[], \"group_counts\":[], \"offline_counts\":[], \"promoted_counts\":[], \"number_files\":[]} \n",
    "                            #create a dictionary within each date for metrics and list for each value\n",
    "        daily_tags[date] = []\n",
    "\n",
    "\n",
    "    # __________________________read CSV file and get metrics________________________________________\n",
    "\n",
    "    df = pd.read_csv(filename) #open the csv as dataframe\n",
    "    files = 1\n",
    "    \n",
    "    all_performers_count = len(df)\n",
    "    \n",
    "    if \"offline\" in df.columns:\n",
    "        offline_count = df.offline.sum()\n",
    "        df = df[df[\"offline\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might exist (ebony), but were removed\")\n",
    "    elif \"away\" in df.columns:\n",
    "        offline_count = df.away.sum()\n",
    "        df = df[df[\"away\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might existe (bonga), but were removed\")\n",
    "    else:\n",
    "        offline_count = 0\n",
    "        #print(\"this plaform does not save offline performers, proceeding >>\")\n",
    "    \n",
    "    \n",
    "    perf_count = len(df) #number of shows in each csv file\n",
    "    print(f\"number of online performers:{perf_count}, number of offline performers: {offline_count}, number of all performers: {all_performers_count}\")\n",
    "    print(all_performers_count - offline_count)\n",
    "    print(f\"is the above number equal to {perf_count}?\")\n",
    "# _______________viewers___________\n",
    "\n",
    "    if \"viewers\" in df.columns:\n",
    "        df['viewers'] = df['viewers'].astype(str) #first make all viewer counts into string\n",
    "        df['viewers'] = df['viewers'].str.replace('+', '') #then remove any \"+\"\" from strings\n",
    "        df[\"viewers\"] = pd.to_numeric(df[\"viewers\"]) #then make them into integers again -- this is to fix bongacams issue of having \"99999+\" as a number of viewers\n",
    "        #df[\"viewers\"] = df[\"viewers\"].astype(int)\n",
    "        view_sum = sum(df[\"viewers\"]) #sum of viewers in each csv file\n",
    "        #print(f\"got sum of viewers chaturbate/bongacams: {view_sum}\")\n",
    "    elif \"room count\" in df.columns:\n",
    "        view_sum = sum(df[\"room_count\"])\n",
    "        #print(f\"got sum of viewers myfreecams: {view_sum}\")    \n",
    "    else:\n",
    "        view_sum = 0\n",
    "        #print(\"no viewer numbers for this platform\")\n",
    "    \n",
    "    #try:\n",
    "    #    show_len_sum = sum(df[\"time\"]) #sum of show time in each csv file\n",
    "    #except:\n",
    "    #    show_len_sum = 0\n",
    "    #    print(\"this platform does not provide show lengths\")\n",
    "    #skipping this part because it is only on chaturbate and is not accurate, because it is not actually show length, \n",
    "    #but how long the performer has been online at the moment of scrape\n",
    "    \n",
    "# _______________gender, couples___________\n",
    "    #this is only for chaturbate:\n",
    "    if \"female\" in df.columns:    #they all go together\n",
    "        female_count = df.female.sum() #number of female performers in chaturbate files\n",
    "        male_count = df.male.sum() #number of male performers\n",
    "        trans_count = df.trans.sum() #number of trans performers\n",
    "        couple_count = df.couple.sum() #number of couples performing\n",
    "\n",
    "    else:\n",
    "        female_count = 0\n",
    "        male_count = 0\n",
    "        trans_count = 0\n",
    "        couple_count = 0\n",
    "        #print(\"this platform does not provide gender indications\")\n",
    "\n",
    "# _______________vibrator use___________\n",
    "    if \"vibrator\" in df.columns:\n",
    "        vibrator_count = df.vibrator.sum() #number of performances with smart vibrators activated \n",
    "    else:\n",
    "        vibrator_count = 0\n",
    "        #print(\"this platform does not provide vibrator indication\")\n",
    "\n",
    "# _______________new performers___________\n",
    "    if \"new\" in df.columns: \n",
    "        new_count = df.new.sum() #number of new performers \n",
    "    else:\n",
    "        new_count = 0\n",
    "        #print(\"this platform does not provide new performer indication\")\n",
    "    \n",
    "# _______________performers in private shows___________   \n",
    "    if \"private\" in df.columns:\n",
    "        private_count = df.private.sum()  #number of performers in a private show at the moment (bongacams)\n",
    "        #print(f\"got bongacams privates: {private_count}\")\n",
    "    elif \"private_show\" in df.columns:\n",
    "        private_count = df.private_show.sum() + df.true_private_show.sum() #number of performers in a private show at the moment (myfreecams)\n",
    "        #print(f\"got myfreecams privates: {private_count}\")\n",
    "    else:\n",
    "        private_count = 0\n",
    "        #print(\"this platform does not provide private show indication\")\n",
    "    \n",
    "# _______________promoted performers___________    \n",
    "\n",
    "    if \"promoted\" in df.columns:\n",
    "        promoted_count = df.promoted.sum()\n",
    "        #print(f\"got promoted performers (livejasmin/chaturbate): {promoted_count}\")\n",
    "    elif \"lifted_up_webcam_model\" in df.columns:\n",
    "        promoted_count = df.lifted_up_webcam_model.sum()\n",
    "        #print(f\"got promoted performers (bongacams): {promoted_count}\")\n",
    "    else:\n",
    "        promoted_count = 0\n",
    "        #print(\"this platform does not provide promoted performer indication\")\n",
    "\n",
    "# _______________performers in group shows___________   \n",
    "    if \"group\" in df.columns:\n",
    "        group_count = df.group.sum() #bonga\n",
    "        #print(f\"got performers in group shows (bongacams): {group_count}\")\n",
    "    elif \"group_show\" in df.columns:\n",
    "        group_count = df.group_show.sum() #myfreecams\n",
    "        #print(f\"got performers in group shows (myfreecams): {group_count}\")\n",
    "    else:\n",
    "        group_count = 0\n",
    "        #print(\"this platform does not provide group show indication\")\n",
    "\n",
    "\n",
    "   # __________________________put metrics in a dictionary________________________________________\n",
    "    # add all the new collected values in the nested dictionary\n",
    "    daily_dict[date][\"perf_counts\"].append(perf_count)\n",
    "    daily_dict[date][\"view_sums\"].append(view_sum)\n",
    "    daily_dict[date][\"female_counts\"].append(female_count)\n",
    "    daily_dict[date][\"male_counts\"].append(male_count)\n",
    "    daily_dict[date][\"trans_counts\"].append(trans_count)\n",
    "    daily_dict[date][\"couple_counts\"].append(couple_count)\n",
    "    daily_dict[date][\"vibrator_counts\"].append(vibrator_count)\n",
    "    daily_dict[date][\"new_counts\"].append(new_count)\n",
    "    daily_dict[date][\"private_counts\"].append(private_count)\n",
    "    daily_dict[date][\"offline_counts\"].append(offline_count)\n",
    "    daily_dict[date][\"promoted_counts\"].append(promoted_count)\n",
    "    daily_dict[date][\"group_counts\"].append(group_count)\n",
    "    daily_dict[date][\"number_files\"].append(files)\n",
    "\n",
    "# __________________________collect hashtags and put in dictionary________________________________________\n",
    "\n",
    "    if \"tags\" in df.columns:\n",
    "        hashtags_list = df[\"tags\"].tolist() #makes a list of all the hashtags used that day\n",
    "        \n",
    "        hashtags = []\n",
    "        for object in hashtags_list:\n",
    "            #print(object)\n",
    "            if type(object) is str:\n",
    "                #print(type(object))\n",
    "                object = object.split(\",\")\n",
    "                for word in object:\n",
    "                    hashtags.append(word)\n",
    "            else:\n",
    "                #print(type(object))\n",
    "                hashtags.append(object)\n",
    "        #print(hashtags)\n",
    "\n",
    "    #add the collected hashtags in their own dictionary\n",
    "        daily_tags[date]+=hashtags\n",
    "\n",
    "    else:\n",
    "        hashtags_list = 0\n",
    "        print(\"this platform does not provide hashtags\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#print(daily_dict)\n",
    "#print(daily_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>number_files</th>\n",
       "      <th>shows_average</th>\n",
       "      <th>offline_average</th>\n",
       "      <th>viewers_average</th>\n",
       "      <th>average_vibrator</th>\n",
       "      <th>percentage_vibrator</th>\n",
       "      <th>average_new</th>\n",
       "      <th>percentage_new</th>\n",
       "      <th>average_promoted</th>\n",
       "      <th>...</th>\n",
       "      <th>average_group</th>\n",
       "      <th>percentage_group</th>\n",
       "      <th>average_females</th>\n",
       "      <th>percentage_females</th>\n",
       "      <th>average_males</th>\n",
       "      <th>percentage_males</th>\n",
       "      <th>average_trans</th>\n",
       "      <th>percentage_trans</th>\n",
       "      <th>average_couples</th>\n",
       "      <th>percentage_couples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>8</td>\n",
       "      <td>2153.75</td>\n",
       "      <td>5310.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>48</td>\n",
       "      <td>2149.73</td>\n",
       "      <td>6869.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>48</td>\n",
       "      <td>2210.77</td>\n",
       "      <td>7025.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>48</td>\n",
       "      <td>2049.98</td>\n",
       "      <td>6677.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>48</td>\n",
       "      <td>1564.12</td>\n",
       "      <td>7556.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>48</td>\n",
       "      <td>1972.58</td>\n",
       "      <td>7297.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>48</td>\n",
       "      <td>2107.10</td>\n",
       "      <td>7314.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>48</td>\n",
       "      <td>2039.92</td>\n",
       "      <td>6853.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>48</td>\n",
       "      <td>2012.75</td>\n",
       "      <td>6846.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>48</td>\n",
       "      <td>1495.19</td>\n",
       "      <td>7750.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  number_files  shows_average  offline_average  viewers_average  \\\n",
       "0   2021-11-03             8        2153.75          5310.25              0.0   \n",
       "1   2021-11-04            48        2149.73          6869.27              0.0   \n",
       "2   2021-11-05            48        2210.77          7025.23              0.0   \n",
       "3   2021-11-06            48        2049.98          6677.02              0.0   \n",
       "4   2021-11-07            48        1564.12          7556.88              0.0   \n",
       "..         ...           ...            ...              ...              ...   \n",
       "62  2022-01-12            48        1972.58          7297.42              0.0   \n",
       "63  2022-01-13            48        2107.10          7314.90              0.0   \n",
       "64  2022-01-14            48        2039.92          6853.08              0.0   \n",
       "65  2022-01-15            48        2012.75          6846.25              0.0   \n",
       "66  2022-01-16            48        1495.19          7750.81              0.0   \n",
       "\n",
       "    average_vibrator  percentage_vibrator  average_new  percentage_new  \\\n",
       "0                0.0                  0.0          0.0             0.0   \n",
       "1                0.0                  0.0          0.0             0.0   \n",
       "2                0.0                  0.0          0.0             0.0   \n",
       "3                0.0                  0.0          0.0             0.0   \n",
       "4                0.0                  0.0          0.0             0.0   \n",
       "..               ...                  ...          ...             ...   \n",
       "62               0.0                  0.0          0.0             0.0   \n",
       "63               0.0                  0.0          0.0             0.0   \n",
       "64               0.0                  0.0          0.0             0.0   \n",
       "65               0.0                  0.0          0.0             0.0   \n",
       "66               0.0                  0.0          0.0             0.0   \n",
       "\n",
       "    average_promoted  ...  average_group  percentage_group  average_females  \\\n",
       "0                0.0  ...            0.0               0.0              0.0   \n",
       "1                0.0  ...            0.0               0.0              0.0   \n",
       "2                0.0  ...            0.0               0.0              0.0   \n",
       "3                0.0  ...            0.0               0.0              0.0   \n",
       "4                0.0  ...            0.0               0.0              0.0   \n",
       "..               ...  ...            ...               ...              ...   \n",
       "62               0.0  ...            0.0               0.0              0.0   \n",
       "63               0.0  ...            0.0               0.0              0.0   \n",
       "64               0.0  ...            0.0               0.0              0.0   \n",
       "65               0.0  ...            0.0               0.0              0.0   \n",
       "66               0.0  ...            0.0               0.0              0.0   \n",
       "\n",
       "    percentage_females  average_males  percentage_males  average_trans  \\\n",
       "0                  0.0            0.0               0.0            0.0   \n",
       "1                  0.0            0.0               0.0            0.0   \n",
       "2                  0.0            0.0               0.0            0.0   \n",
       "3                  0.0            0.0               0.0            0.0   \n",
       "4                  0.0            0.0               0.0            0.0   \n",
       "..                 ...            ...               ...            ...   \n",
       "62                 0.0            0.0               0.0            0.0   \n",
       "63                 0.0            0.0               0.0            0.0   \n",
       "64                 0.0            0.0               0.0            0.0   \n",
       "65                 0.0            0.0               0.0            0.0   \n",
       "66                 0.0            0.0               0.0            0.0   \n",
       "\n",
       "    percentage_trans  average_couples  percentage_couples  \n",
       "0                0.0                0                 0.0  \n",
       "1                0.0                0                 0.0  \n",
       "2                0.0                0                 0.0  \n",
       "3                0.0                0                 0.0  \n",
       "4                0.0                0                 0.0  \n",
       "..               ...              ...                 ...  \n",
       "62               0.0                0                 0.0  \n",
       "63               0.0                0                 0.0  \n",
       "64               0.0                0                 0.0  \n",
       "65               0.0                0                 0.0  \n",
       "66               0.0                0                 0.0  \n",
       "\n",
       "[67 rows x 23 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_avgs = []\n",
    "\n",
    "# next step is to iterate over array to calculate daily averages and counts\n",
    "\n",
    "for date in daily_dict:  #for each date calculate:\n",
    "    daily_files_sum = np.sum(daily_dict[date][\"number_files\"])\n",
    "    daily_shows_avg = np.mean(daily_dict[date][\"perf_counts\"]) #average length of page (number of performances - the ones that are online) (all platforms)\n",
    "    daily_offline_avg = np.mean(daily_dict[date][\"offline_counts\"]) #average of how many people on the list were offline (bongacams and myfreecams)\n",
    "    daily_views_avg = sum(daily_dict[date][\"view_sums\"]) / sum(daily_dict[date][\"perf_counts\"]) #average number of viewers per day (chaturbate, bongacams and myfreecams)\n",
    "    \n",
    "    daily_female_avg = np.mean(daily_dict[date][\"female_counts\"]) #only chaturbate\n",
    "    daily_female_percent = sum(daily_dict[date][\"female_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    daily_male_avg = np.mean(daily_dict[date][\"male_counts\"]) #only chaturbate\n",
    "    daily_male_percent = sum(daily_dict[date][\"male_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    daily_trans_avg = np.mean(daily_dict[date][\"trans_counts\"]) #only chaturbate\n",
    "    daily_trans_percent = sum(daily_dict[date][\"trans_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    daily_couple_avg = np.mean(daily_dict[date][\"couple_counts\"]) #only chaturbate\n",
    "    daily_couple_percent = sum(daily_dict[date][\"couple_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    \n",
    "    daily_vibrator_avg = np.mean(daily_dict[date][\"vibrator_counts\"]) #(bongacams and livejasmin)\n",
    "    daily_vibrator_percent = sum(daily_dict[date][\"vibrator_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #(bongacams and livejasmin)\n",
    "    daily_new_avg = np.mean(daily_dict[date][\"new_counts\"]) #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    daily_new_percent = sum(daily_dict[date][\"new_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    daily_promoted_avg = np.mean(daily_dict[date][\"promoted_counts\"]) #bongacams, livejasmin, chaturbate\n",
    "    daily_promoted_percent = sum(daily_dict[date][\"promoted_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams, livejasmin, chaturbate\n",
    "\n",
    "    daily_private_avg = np.mean(daily_dict[date][\"private_counts\"]) #bongacams and myfreecams\n",
    "    daily_private_percent = sum(daily_dict[date][\"private_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "    daily_group_avg = np.mean(daily_dict[date][\"group_counts\"]) #bongacams and myfreecams\n",
    "    daily_group_percent = sum(daily_dict[date][\"group_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "\n",
    "\n",
    "    #then add everything to a nice dictionary\n",
    "    daily_avgs.append({'date':date, 'number_files': daily_files_sum, 'shows_average':round(daily_shows_avg, 2), 'offline_average':round(daily_offline_avg, 2), 'viewers_average':round(daily_views_avg, 2),\n",
    "    'average_vibrator':round(daily_vibrator_avg,2), 'percentage_vibrator':round(daily_vibrator_percent,2), 'average_new':round(daily_new_avg,2), 'percentage_new':round(daily_new_percent,2),\n",
    "    'average_promoted':round(daily_promoted_avg,2), 'percentage_promoted':round(daily_promoted_percent,2), 'average_private':round(daily_private_avg,2), 'percentage_private':round(daily_private_percent,2),\n",
    "    'average_group':round(daily_group_avg,2), 'percentage_group':round(daily_group_percent,2), 'average_females':round(daily_female_avg,2), 'percentage_females':round(daily_female_percent,2), \n",
    "    'average_males':round(daily_male_avg,2), 'percentage_males':round(daily_male_percent,2), 'average_trans':round(daily_trans_avg,2), 'percentage_trans':round(daily_trans_percent,2), \n",
    "    'average_couples':round(daily_couple_avg), 'percentage_couples':round(daily_couple_percent,2)})\n",
    "    #print(daily_avgs)\n",
    "\n",
    "#and make a dataframe from the dictionary\n",
    "df = pd.DataFrame.from_dict(daily_avgs)\n",
    "df.to_csv('daily_metrics_ebonycams.csv',index=False) #and save it as a csv file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here i make a file with the counted hashtags over time\n",
    "# FUTURE: not include all hashtags, but only those that are counted above a threshold?\n",
    "\n",
    "daily_tags_counted = []\n",
    "\n",
    "for date in daily_tags:  #iterating though every date\n",
    "    daily_counts = Counter(daily_tags[date]) #instead of having a list of all hashtags, this makes a dictionary with counts of each hashtag\n",
    "    #print(daily_counts)\n",
    "\n",
    "    for tag in daily_counts: \n",
    "        daily_tags_counted.append({\"date\": date, \"hashtag\": tag , \"count\": daily_counts[tag]})\n",
    "        #daily_tags_counted[date][tag] = daily_counts[tag]\n",
    "\n",
    "df = pd.DataFrame.from_dict(daily_tags_counted)\n",
    "df.to_csv('daily_hashtags_ebonycams.csv',index=False)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics per half an hour in day\n",
    "- next, we use a similar approach to look at metrics per hour and analyze performer work \"rhythms\" during different times of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the master dictionary for collecting hourly data\n",
    "hourly_dict = {}\n",
    "#IF HASHTAGS ARE INTERESTING PER TIME IN DAY, THEN HERE THAT SHOULD BE ADDED THE SAME WAY AS IN METRICS PER DAY\n",
    "counter = 1\n",
    "\n",
    "\n",
    "# iterate over all files to create an array of lists with all metrics for each hour in a day\n",
    "for filename in sorted(csv_files):\n",
    "\n",
    "    #print(filename)\n",
    "    fileparts = filename.split('_')\n",
    "    smaller_parts = fileparts[1].split('/')\n",
    "    platform_split = smaller_parts[2].split('2')\n",
    "    platform = platform_split[0]\n",
    "    #print(platform)\n",
    "    \n",
    "    if platform == \"myfreecams\":\n",
    "        time = fileparts[2]\n",
    "        print(time)\n",
    "    else:\n",
    "        time = fileparts[3]\n",
    "        print(time)\n",
    "   \n",
    "    timeparts = time.split('-')\n",
    "    hour = f\"0000-00-00 {timeparts[0]}:{timeparts[1]}:00\"\n",
    "    #print(hour)\n",
    "    \n",
    "    print(str(counter) + ' ' + hour + ' ' + platform)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "    if hour not in hourly_dict: #add the hour to a dictionary with keys for each hour\n",
    "        hourly_dict[hour] = {\"perf_counts\":[], \"view_sums\":[], \"show_length_sums\":[], \"female_counts\":[], \"male_counts\":[], \"trans_counts\":[], \"couple_counts\":[], \n",
    "                            \"vibrator_counts\":[], \"new_counts\":[], \"private_counts\":[], \"group_counts\":[], \"offline_counts\":[], \"promoted_counts\":[], \"number_files\":[]} \n",
    "                            #create a dictionary within each date for metrics and list for each value\n",
    "\n",
    "\n",
    "    # __________________________read CSV file and get metrics________________________________________\n",
    "    # this obviously could be done together with hourly metrics, so the files don't need to be opened twice, but for now i am keeping it this way\n",
    "    # because i already have run the metrics for days in the timeframe\n",
    "\n",
    "    df = pd.read_csv(filename) #open the csv as dataframe\n",
    "    files = 1\n",
    "    \n",
    "    all_performers_count = len(df)\n",
    "    \n",
    "    if \"offline\" in df.columns:\n",
    "        offline_count = df.offline.sum()\n",
    "        df = df[df[\"offline\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might exist (ebony), but were removed\")\n",
    "    elif \"away\" in df.columns:\n",
    "        offline_count = df.away.sum()\n",
    "        df = df[df[\"away\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might existe (bonga), but were removed\")\n",
    "    else:\n",
    "        offline_count = 0\n",
    "        #print(\"this plaform does not save offline performers, proceeding >>\")\n",
    "    \n",
    "    \n",
    "    perf_count = len(df) #number of shows in each csv file\n",
    "    print(f\"number of online performers:{perf_count}, number of offline performers: {offline_count}, number of all performers: {all_performers_count}\")\n",
    "    print(f\"{perf_count}?\")\n",
    "    print(all_performers_count - offline_count)\n",
    "    \n",
    "# _______________viewers___________\n",
    "\n",
    "    if \"viewers\" in df.columns:\n",
    "        df['viewers'] = df['viewers'].astype(str) #first make all viewer counts into string\n",
    "        df['viewers'] = df['viewers'].str.replace('+', '') #then remove any \"+\"\" from strings\n",
    "        df[\"viewers\"] = pd.to_numeric(df[\"viewers\"]) #then make them into integers again -- this is to fix bongacams issue of having \"99999+\" as a number of viewers\n",
    "        #df[\"viewers\"] = df[\"viewers\"].astype(int)\n",
    "        view_sum = sum(df[\"viewers\"]) #sum of viewers in each csv file\n",
    "        #print(f\"got sum of viewers chaturbate/bongacams: {view_sum}\")\n",
    "    elif \"room count\" in df.columns:\n",
    "        view_sum = sum(df[\"room_count\"])\n",
    "        #print(f\"got sum of viewers myfreecams: {view_sum}\")    \n",
    "    else:\n",
    "        view_sum = 0\n",
    "        #print(\"no viewer numbers for this platform\")\n",
    "    \n",
    "    #try:\n",
    "    #    show_len_sum = sum(df[\"time\"]) #sum of show time in each csv file\n",
    "    #except:\n",
    "    #    show_len_sum = 0\n",
    "    #    print(\"this platform does not provide show lengths\")\n",
    "    #skipping this part because it is only on chaturbate and is not accurate, because it is not actually show length, \n",
    "    #but how long the performer has been online at the moment of scrape\n",
    "    \n",
    "# _______________gender, couples___________\n",
    "    #this is only for chaturbate:\n",
    "    if \"female\" in df.columns:    #they all go together\n",
    "        female_count = df.female.sum() #number of female performers in chaturbate files\n",
    "        male_count = df.male.sum() #number of male performers\n",
    "        trans_count = df.trans.sum() #number of trans performers\n",
    "        couple_count = df.couple.sum() #number of couples performing\n",
    "\n",
    "    else:\n",
    "        female_count = 0\n",
    "        male_count = 0\n",
    "        trans_count = 0\n",
    "        couple_count = 0\n",
    "        #print(\"this platform does not provide gender indications\")\n",
    "\n",
    "# _______________vibrator use___________\n",
    "    if \"vibrator\" in df.columns:\n",
    "        vibrator_count = df.vibrator.sum() #number of performances with smart vibrators activated \n",
    "    else:\n",
    "        vibrator_count = 0\n",
    "        #print(\"this platform does not provide vibrator indication\")\n",
    "\n",
    "# _______________new performers___________\n",
    "    if \"new\" in df.columns: \n",
    "        new_count = df.new.sum() #number of new performers \n",
    "    else:\n",
    "        new_count = 0\n",
    "        #print(\"this platform does not provide new performer indication\")\n",
    "    \n",
    "# _______________performers in private shows___________   \n",
    "    if \"private\" in df.columns:\n",
    "        private_count = df.private.sum()  #number of performers in a private show at the moment (bongacams)\n",
    "        #print(f\"got bongacams privates: {private_count}\")\n",
    "    elif \"private_show\" in df.columns:\n",
    "        private_count = df.private_show.sum() + df.true_private_show.sum() #number of performers in a private show at the moment (myfreecams)\n",
    "        #print(f\"got myfreecams privates: {private_count}\")\n",
    "    else:\n",
    "        private_count = 0\n",
    "        #print(\"this platform does not provide private show indication\")\n",
    "    \n",
    "# _______________promoted performers___________    \n",
    "\n",
    "    if \"promoted\" in df.columns:\n",
    "        promoted_count = df.promoted.sum()\n",
    "        #print(f\"got promoted performers (livejasmin/chaturbate): {promoted_count}\")\n",
    "    elif \"lifted_up_webcam_model\" in df.columns:\n",
    "        promoted_count = df.lifted_up_webcam_model.sum()\n",
    "        #print(f\"got promoted performers (bongacams): {promoted_count}\")\n",
    "    else:\n",
    "        promoted_count = 0\n",
    "        #print(\"this platform does not provide promoted performer indication\")\n",
    "\n",
    "# _______________performers in group shows___________   \n",
    "    if \"group\" in df.columns:\n",
    "        group_count = df.group.sum() #bonga\n",
    "        #print(f\"got performers in group shows (bongacams): {group_count}\")\n",
    "    elif \"group_show\" in df.columns:\n",
    "        group_count = df.group_show.sum() #myfreecams\n",
    "        #print(f\"got performers in group shows (myfreecams): {group_count}\")\n",
    "    else:\n",
    "        group_count = 0\n",
    "        #print(\"this platform does not provide group show indication\")\n",
    "\n",
    "\n",
    "   # __________________________put metrics in a dictionary________________________________________\n",
    "    # add all the new collected values in the nested dictionary\n",
    "    hourly_dict[hour][\"perf_counts\"].append(perf_count)\n",
    "    hourly_dict[hour][\"view_sums\"].append(view_sum)\n",
    "    hourly_dict[hour][\"female_counts\"].append(female_count)\n",
    "    hourly_dict[hour][\"male_counts\"].append(male_count)\n",
    "    hourly_dict[hour][\"trans_counts\"].append(trans_count)\n",
    "    hourly_dict[hour][\"couple_counts\"].append(couple_count)\n",
    "    hourly_dict[hour][\"vibrator_counts\"].append(vibrator_count)\n",
    "    hourly_dict[hour][\"new_counts\"].append(new_count)\n",
    "    hourly_dict[hour][\"private_counts\"].append(private_count)\n",
    "    hourly_dict[hour][\"offline_counts\"].append(offline_count)\n",
    "    hourly_dict[hour][\"promoted_counts\"].append(promoted_count)\n",
    "    hourly_dict[hour][\"group_counts\"].append(group_count)\n",
    "    hourly_dict[hour][\"number_files\"].append(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_avgs = []\n",
    "\n",
    "# next step is to iterate over array to calculate hourly metrics\n",
    "for hour in hourly_dict:  #for each hour in day calculate:\n",
    "    hourly_files_sum = np.sum(hourly_dict[hour][\"number_files\"])\n",
    "    hourly_shows_avg = np.mean(hourly_dict[hour][\"perf_counts\"]) #average length of page (number of performances - the ones that are online) (all platforms)\n",
    "    hourly_offline_avg = np.mean(hourly_dict[hour][\"offline_counts\"]) #average of how many people on the list were offline (bongacams and myfreecams)\n",
    "    hourly_views_avg = sum(hourly_dict[hour][\"view_sums\"]) / sum(hourly_dict[hour][\"perf_counts\"]) #average number of viewers per day (chaturbate, bongacams and myfreecams)\n",
    "    \n",
    "    hourly_female_avg = np.mean(hourly_dict[hour][\"female_counts\"]) #only chaturbate\n",
    "    hourly_female_percent = sum(hourly_dict[hour][\"female_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    hourly_male_avg = np.mean(hourly_dict[hour][\"male_counts\"]) #only chaturbate\n",
    "    hourly_male_percent = sum(hourly_dict[hour][\"male_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    hourly_trans_avg = np.mean(hourly_dict[hour][\"trans_counts\"]) #only chaturbate\n",
    "    hourly_trans_percent = sum(hourly_dict[hour][\"trans_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    hourly_couple_avg = np.mean(hourly_dict[hour][\"couple_counts\"]) #only chaturbate\n",
    "    hourly_couple_percent = sum(hourly_dict[hour][\"couple_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    \n",
    "    hourly_vibrator_avg = np.mean(hourly_dict[hour][\"vibrator_counts\"]) #(bongacams and livejasmin)\n",
    "    hourly_vibrator_percent = sum(hourly_dict[hour][\"vibrator_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #(bongacams and livejasmin)\n",
    "    hourly_new_avg = np.mean(hourly_dict[hour][\"new_counts\"]) #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    hourly_new_percent = sum(hourly_dict[hour][\"new_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    hourly_promoted_avg = np.mean(hourly_dict[hour][\"promoted_counts\"]) #bongacams, livejasmin, chaturbate\n",
    "    hourly_promoted_percent = sum(hourly_dict[hour][\"promoted_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams, livejasmin, chaturbate\n",
    "\n",
    "    hourly_private_avg = np.mean(hourly_dict[hour][\"private_counts\"]) #bongacams and myfreecams\n",
    "    hourly_private_percent = sum(hourly_dict[hour][\"private_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "    hourly_group_avg = np.mean(hourly_dict[hour][\"group_counts\"]) #bongacams and myfreecams\n",
    "    hourly_group_percent = sum(hourly_dict[hour][\"group_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "\n",
    "\n",
    "    #then add everything to a nice dictionary\n",
    "    hourly_avgs.append({'hour':hour, 'number_files': hourly_files_sum, 'shows_average':round(hourly_shows_avg, 2), 'offline_average':round(hourly_offline_avg, 2), 'viewers_average':round(hourly_views_avg, 2),\n",
    "    'average_vibrator':round(hourly_vibrator_avg,2), 'percentage_vibrator':round(hourly_vibrator_percent,2), 'average_new':round(hourly_new_avg,2), 'percentage_new':round(hourly_new_percent,2),\n",
    "    'average_promoted':round(hourly_promoted_avg,2), 'percentage_promoted':round(hourly_promoted_percent,2), 'average_private':round(hourly_private_avg,2), 'percentage_private':round(hourly_private_percent,2),\n",
    "    'average_group':round(hourly_group_avg,2), 'percentage_group':round(hourly_group_percent,2), 'average_females':round(hourly_female_avg,2), 'percentage_females':round(hourly_female_percent,2), \n",
    "    'average_males':round(hourly_male_avg,2), 'percentage_males':round(hourly_male_percent,2), 'average_trans':round(hourly_trans_avg,2), 'percentage_trans':round(hourly_trans_percent,2), \n",
    "    'average_couples':round(hourly_couple_avg), 'percentage_couples':round(hourly_couple_percent,2)})\n",
    "    #print(hourly_avgs)\n",
    "\n",
    "#and make a dataframe from the dictionary\n",
    "df = pd.DataFrame.from_dict(hourly_avgs)\n",
    "#df.to_csv('hourly_metrics_myfreecams.csv',index=False) #and save it as a csv file\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
