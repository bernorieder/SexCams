{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below choose which directory to work with (all files or test files)\n",
    "\n",
    "path = 'homepage_csvs/test.myfreecams/' #change platform name after full stop to choose which test files to use\n",
    "#path = 'homepage_csvs/chaturbate/'\n",
    "#path = 'homepage_csvs/myfreecams/'\n",
    "#path = 'homepage_csvs/bongacams/'\n",
    "#path = 'homepage_csvs/livejasmin/'\n",
    "#path = 'homepage_csvs/streamate/'\n",
    "#path = 'homepage_csvs/ebonycams/'\n",
    "\n",
    "#DEPENDING ON THE PLATFORM, MAKE SURE TO ALSO DEAL WITH FILE NAMES OF SAVED CSV LATER!\n",
    "\n",
    "# get all filenames from the directory\n",
    "csv_files = glob.glob(path + '*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting needed metrics from csv files\n",
    "- this is code for reading multiple frontpage files and calculating metrics per timestamp\n",
    "- code is based on the example from \"basic_file_read\" by Bernhard\n",
    "- we collect metrics: for each day in the studied timeframe and also for each hour in 24hrs, not separating per date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "daily_dict = {} #create an empty dictionary to store all metrics for daily calculations\n",
    "daily_tags = {} #create an empty dictionary to store a list of all hashtags per day\n",
    "hourly_dict = {} #make the master dictionary for collecting hourly data\n",
    "#IF HASHTAGS ARE INTERESTING PER TIME IN DAY, THEN HERE THAT SHOULD BE ADDED THE SAME WAY AS IN METRICS PER DAY\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# iterate over all files to create an array of lists with all metrics for each day\n",
    "for filename in sorted(csv_files):\n",
    "\n",
    "    # extract date from filename\n",
    "    #print(filename)\n",
    "    fileparts = filename.split('_')\n",
    "    smaller_parts = fileparts[1].split('/')\n",
    "    platform_split = smaller_parts[2].split('2')\n",
    "    platform = platform_split[0]\n",
    "    #print(platform)\n",
    "    \n",
    "    # myfreecams has no underscore after platform name, so the date/time extraction is different:\n",
    "    if platform == \"myfreecams\":\n",
    "        myfreecams_split = smaller_parts[2].split('myfreecams')\n",
    "        date = myfreecams_split[1]\n",
    "        time = fileparts[2]\n",
    "        #print(time)\n",
    "        #print(date)\n",
    "    else: #for the rest of the platforms it's simple:\n",
    "        date = fileparts[2]\n",
    "        time = fileparts[3]\n",
    "        #print(time)\n",
    "        #print(date)\n",
    "\n",
    "\n",
    "    timeparts = time.split('-')\n",
    "    hour = f\"0000-00-00 {timeparts[0]}:{timeparts[1]}:00\" #the weird format is because i need that for some visualizations\n",
    "    #print(hour)\n",
    "    \n",
    "    print(f\"{counter} platform:{platform} date:{date} time:{hour}\")\n",
    "    counter += 1\n",
    "\n",
    "    if date not in daily_dict: #add the date to a dictionary with keys for each date\n",
    "        daily_dict[date] = {\"perf_counts\":[], \"view_sums\":[], \"show_length_sums\":[], \"female_counts\":[], \"male_counts\":[], \"trans_counts\":[], \"couple_counts\":[], \n",
    "                            \"vibrator_counts\":[], \"new_counts\":[], \"private_counts\":[], \"group_counts\":[], \"offline_counts\":[], \"promoted_counts\":[], \"number_files\":[]} \n",
    "                            #create a dictionary within each date for metrics and list for each value\n",
    "        daily_tags[date] = [] #daily also creating hashtags, but not by hour\n",
    "\n",
    "    \n",
    "    if hour not in hourly_dict: #add the hour to a dictionary with keys for each hour\n",
    "        hourly_dict[hour] = {\"perf_counts\":[], \"view_sums\":[], \"show_length_sums\":[], \"female_counts\":[], \"male_counts\":[], \"trans_counts\":[], \"couple_counts\":[], \n",
    "                            \"vibrator_counts\":[], \"new_counts\":[], \"private_counts\":[], \"group_counts\":[], \"offline_counts\":[], \"promoted_counts\":[], \"number_files\":[]} \n",
    "                            #create a dictionary within each halfhour for metrics and list for each value\n",
    "\n",
    "\n",
    "    # __________________________read CSV file and get metrics________________________________________\n",
    "\n",
    "    df = pd.read_csv(filename) #open the csv as dataframe\n",
    "    files = 1\n",
    "    \n",
    "    all_performers_count = len(df)\n",
    "    \n",
    "    if \"offline\" in df.columns:\n",
    "        offline_count = df.offline.sum()\n",
    "        df = df[df[\"offline\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might exist (ebony), but were removed\")\n",
    "    elif \"away\" in df.columns:\n",
    "        offline_count = df.away.sum()\n",
    "        df = df[df[\"away\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might existe (bonga), but were removed\")\n",
    "    else:\n",
    "        offline_count = 0\n",
    "        #print(\"this plaform does not save offline performers, proceeding >>\")\n",
    "    \n",
    "    \n",
    "    perf_count = len(df) #number of shows in each csv file\n",
    "    print(f\"number of online performers:{perf_count}, number of offline performers: {offline_count}, number of all performers: {all_performers_count}\")\n",
    "    print(f\"{perf_count}?\")\n",
    "    print(all_performers_count - offline_count) #check if i did not fuck up by checking if the numbers are the same\n",
    "    \n",
    "# _______________viewers___________\n",
    "\n",
    "    if \"viewers\" in df.columns:\n",
    "        df['viewers'] = df['viewers'].astype(str) #first make all viewer counts into string\n",
    "        df['viewers'] = df['viewers'].str.replace('+', '') #then remove any \"+\"\" from strings\n",
    "        df[\"viewers\"] = pd.to_numeric(df[\"viewers\"]) #then make them into integers again -- this is to fix bongacams issue of having \"99999+\" as a number of viewers\n",
    "        #df[\"viewers\"] = df[\"viewers\"].astype(int)\n",
    "        view_sum = df[\"viewers\"].sum() #sum of viewers in each csv file\n",
    "        #print(f\"got sum of viewers chaturbate/bongacams: {view_sum}\")\n",
    "    elif \"room_count\" in df.columns:\n",
    "        view_sum = df[\"room_count\"].sum()\n",
    "        #print(f\"got sum of viewers myfreecams: {view_sum}\")    \n",
    "    else:\n",
    "        view_sum = 0\n",
    "        #print(\"no viewer numbers for this platform\")\n",
    "    \n",
    "    #try:\n",
    "    #    show_len_sum = sum(df[\"time\"]) #sum of show time in each csv file\n",
    "    #except:\n",
    "    #    show_len_sum = 0\n",
    "    #    print(\"this platform does not provide show lengths\")\n",
    "    #skipping this part because it is only on chaturbate and is not accurate, because it is not actually show length, \n",
    "    #but how long the performer has been online at the moment of scrape\n",
    "    \n",
    "# _______________gender, couples___________\n",
    "    #this is only for chaturbate:\n",
    "    if \"female\" in df.columns:    #they all go together\n",
    "        female_count = df.female.sum() #number of female performers in chaturbate files\n",
    "        male_count = df.male.sum() #number of male performers\n",
    "        trans_count = df.trans.sum() #number of trans performers\n",
    "        couple_count = df.couple.sum() #number of couples performing\n",
    "\n",
    "    else:\n",
    "        female_count = 0\n",
    "        male_count = 0\n",
    "        trans_count = 0\n",
    "        couple_count = 0\n",
    "        #print(\"this platform does not provide gender indications\")\n",
    "\n",
    "# _______________vibrator use___________\n",
    "    if \"vibrator\" in df.columns:\n",
    "        vibrator_count = df.vibrator.sum() #number of performances with smart vibrators activated \n",
    "    else:\n",
    "        vibrator_count = 0\n",
    "        #print(\"this platform does not provide vibrator indication\")\n",
    "\n",
    "# _______________new performers___________\n",
    "    if \"new\" in df.columns: \n",
    "        new_count = df.new.sum() #number of new performers \n",
    "    else:\n",
    "        new_count = 0\n",
    "        #print(\"this platform does not provide new performer indication\")\n",
    "    \n",
    "# _______________performers in private shows___________   \n",
    "    if \"private\" in df.columns:\n",
    "        private_count = df.private.sum()  #number of performers in a private show at the moment (bongacams)\n",
    "        #print(f\"got bongacams privates: {private_count}\")\n",
    "    elif \"private_show\" in df.columns:\n",
    "        private_count = df.private_show.sum() + df.true_private_show.sum() #number of performers in a private show at the moment (myfreecams)\n",
    "        #print(f\"got myfreecams privates: {private_count}\")\n",
    "    else:\n",
    "        private_count = 0\n",
    "        #print(\"this platform does not provide private show indication\")\n",
    "    \n",
    "# _______________promoted performers___________    \n",
    "\n",
    "    if \"promoted\" in df.columns:\n",
    "        promoted_count = df.promoted.sum()\n",
    "        #print(f\"got promoted performers (livejasmin/chaturbate): {promoted_count}\")\n",
    "    elif \"lifted_up_webcam_model\" in df.columns:\n",
    "        promoted_count = df.lifted_up_webcam_model.sum()\n",
    "        #print(f\"got promoted performers (bongacams): {promoted_count}\")\n",
    "    else:\n",
    "        promoted_count = 0\n",
    "        #print(\"this platform does not provide promoted performer indication\")\n",
    "\n",
    "# _______________performers in group shows___________   \n",
    "    if \"group\" in df.columns:\n",
    "        group_count = df.group.sum() #bonga\n",
    "        #print(f\"got performers in group shows (bongacams): {group_count}\")\n",
    "    elif \"group_show\" in df.columns:\n",
    "        group_count = df.group_show.sum() #myfreecams\n",
    "        #print(f\"got performers in group shows (myfreecams): {group_count}\")\n",
    "    else:\n",
    "        group_count = 0\n",
    "        #print(\"this platform does not provide group show indication\")\n",
    "\n",
    "\n",
    "   # __________________________put metrics in a dictionary________________________________________\n",
    "    # add all the new collected values in the nested dictionary for each day\n",
    "    daily_dict[date][\"perf_counts\"].append(perf_count)\n",
    "    daily_dict[date][\"view_sums\"].append(view_sum)\n",
    "    daily_dict[date][\"female_counts\"].append(female_count)\n",
    "    daily_dict[date][\"male_counts\"].append(male_count)\n",
    "    daily_dict[date][\"trans_counts\"].append(trans_count)\n",
    "    daily_dict[date][\"couple_counts\"].append(couple_count)\n",
    "    daily_dict[date][\"vibrator_counts\"].append(vibrator_count)\n",
    "    daily_dict[date][\"new_counts\"].append(new_count)\n",
    "    daily_dict[date][\"private_counts\"].append(private_count)\n",
    "    daily_dict[date][\"offline_counts\"].append(offline_count)\n",
    "    daily_dict[date][\"promoted_counts\"].append(promoted_count)\n",
    "    daily_dict[date][\"group_counts\"].append(group_count)\n",
    "    daily_dict[date][\"number_files\"].append(files)\n",
    "    print(\"collected daily metrics\")\n",
    "\n",
    "    # add all the new collected values in the nested dictionary for each hour in 24hrs\n",
    "    hourly_dict[hour][\"perf_counts\"].append(perf_count)\n",
    "    hourly_dict[hour][\"view_sums\"].append(view_sum)\n",
    "    hourly_dict[hour][\"female_counts\"].append(female_count)\n",
    "    hourly_dict[hour][\"male_counts\"].append(male_count)\n",
    "    hourly_dict[hour][\"trans_counts\"].append(trans_count)\n",
    "    hourly_dict[hour][\"couple_counts\"].append(couple_count)\n",
    "    hourly_dict[hour][\"vibrator_counts\"].append(vibrator_count)\n",
    "    hourly_dict[hour][\"new_counts\"].append(new_count)\n",
    "    hourly_dict[hour][\"private_counts\"].append(private_count)\n",
    "    hourly_dict[hour][\"offline_counts\"].append(offline_count)\n",
    "    hourly_dict[hour][\"promoted_counts\"].append(promoted_count)\n",
    "    hourly_dict[hour][\"group_counts\"].append(group_count)\n",
    "    hourly_dict[hour][\"number_files\"].append(files)\n",
    "    print(\"collected hourly metrics\")\n",
    "\n",
    "\n",
    "\n",
    "# __________________________collect hashtags per day and put in dictionary________________________________________\n",
    "\n",
    "    if \"tags\" in df.columns:\n",
    "        hashtags_list = df[\"tags\"].tolist() #makes a list of all the hashtags used that day\n",
    "        \n",
    "        hashtags = []\n",
    "        for object in hashtags_list:\n",
    "            #print(object)\n",
    "            if type(object) is str:\n",
    "                #print(type(object))\n",
    "                object = object.split(\",\")\n",
    "                for word in object:\n",
    "                    hashtags.append(word)\n",
    "            else:\n",
    "                #print(type(object))\n",
    "                hashtags.append(object)\n",
    "        #print(hashtags)\n",
    "\n",
    "    #add the collected hashtags in their own dictionary\n",
    "        daily_tags[date]+=hashtags\n",
    "        print(\"collected daily hashtags\")\n",
    "    else:\n",
    "        hashtags_list = 0\n",
    "        print(\"this platform does not provide hashtags\")\n",
    "\n",
    "\n",
    "#print(daily_dict)\n",
    "#print(hourly_dict)\n",
    "#print(daily_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making daily metrics output file with calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avgs = []\n",
    "\n",
    "# next step is to iterate over array to calculate daily averages and counts\n",
    "\n",
    "for date in daily_dict:  #for each date calculate:\n",
    "    daily_files_sum = np.sum(daily_dict[date][\"number_files\"]) #how many files collected for that day\n",
    "    daily_shows_avg = np.mean(daily_dict[date][\"perf_counts\"]) #average length of page (number of performances - the ones that are online) (all platforms)\n",
    "    daily_offline_avg = np.mean(daily_dict[date][\"offline_counts\"]) #average of how many people on the list were offline (bongacams and myfreecams)\n",
    "    daily_views_sum = sum(daily_dict[date][\"view_sums\"]) #sum of all viewers that day (chaturbate, bongacams and myfreecams)\n",
    "    daily_views_sum_avg = daily_views_sum / daily_files_sum #added this now -- average of total viewers on the platform that day (chaturbate, bongacams and myfreecams)\n",
    "    daily_views_avg = daily_views_sum / sum(daily_dict[date][\"perf_counts\"]) #average number of viewers in a show that day (chaturbate, bongacams and myfreecams)\n",
    "    \n",
    "    daily_female_avg = np.mean(daily_dict[date][\"female_counts\"]) #only chaturbate\n",
    "    daily_female_percent = sum(daily_dict[date][\"female_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    daily_male_avg = np.mean(daily_dict[date][\"male_counts\"]) #only chaturbate\n",
    "    daily_male_percent = sum(daily_dict[date][\"male_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    daily_trans_avg = np.mean(daily_dict[date][\"trans_counts\"]) #only chaturbate\n",
    "    daily_trans_percent = sum(daily_dict[date][\"trans_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    daily_couple_avg = np.mean(daily_dict[date][\"couple_counts\"]) #only chaturbate\n",
    "    daily_couple_percent = sum(daily_dict[date][\"couple_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    \n",
    "    daily_vibrator_avg = np.mean(daily_dict[date][\"vibrator_counts\"]) #(bongacams and livejasmin)\n",
    "    daily_vibrator_percent = sum(daily_dict[date][\"vibrator_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #(bongacams and livejasmin)\n",
    "    daily_new_avg = np.mean(daily_dict[date][\"new_counts\"]) #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    daily_new_percent = sum(daily_dict[date][\"new_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    daily_promoted_avg = np.mean(daily_dict[date][\"promoted_counts\"]) #bongacams, livejasmin, chaturbate\n",
    "    daily_promoted_percent = sum(daily_dict[date][\"promoted_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams, livejasmin, chaturbate\n",
    "\n",
    "    daily_private_avg = np.mean(daily_dict[date][\"private_counts\"]) #bongacams and myfreecams\n",
    "    daily_private_percent = sum(daily_dict[date][\"private_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "    daily_group_avg = np.mean(daily_dict[date][\"group_counts\"]) #bongacams and myfreecams\n",
    "    daily_group_percent = sum(daily_dict[date][\"group_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "\n",
    "\n",
    "    #then add everything to a nice dictionary\n",
    "    daily_avgs.append({'date':date, 'number_files': daily_files_sum, 'shows_average':round(daily_shows_avg, 2), 'offline_average':round(daily_offline_avg, 2), \n",
    "    'viewers_sum':daily_views_sum , 'viewers_sum_avg':round(daily_views_sum_avg, 2), 'viewers_average_in_show':round(daily_views_avg, 2),\n",
    "    'average_vibrator':round(daily_vibrator_avg,2), 'percentage_vibrator':round(daily_vibrator_percent,2), 'average_new':round(daily_new_avg,2), 'percentage_new':round(daily_new_percent,2),\n",
    "    'average_promoted':round(daily_promoted_avg,2), 'percentage_promoted':round(daily_promoted_percent,2), 'average_private':round(daily_private_avg,2), 'percentage_private':round(daily_private_percent,2),\n",
    "    'average_group':round(daily_group_avg,2), 'percentage_group':round(daily_group_percent,2), 'average_females':round(daily_female_avg,2), 'percentage_females':round(daily_female_percent,2), \n",
    "    'average_males':round(daily_male_avg,2), 'percentage_males':round(daily_male_percent,2), 'average_trans':round(daily_trans_avg,2), 'percentage_trans':round(daily_trans_percent,2), \n",
    "    'average_couples':round(daily_couple_avg), 'percentage_couples':round(daily_couple_percent,2)})\n",
    "    #print(daily_avgs)\n",
    "\n",
    "#and make a dataframe from the dictionary\n",
    "df = pd.DataFrame.from_dict(daily_avgs)\n",
    "#df.to_csv('daily_metrics_myfreecams.csv',index=False) #and save it as a csv file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here i make a file with the counted hashtags per day\n",
    "# FUTURE: not include all hashtags, but only those that are counted above a threshold?\n",
    "\n",
    "daily_tags_counted = []\n",
    "\n",
    "for date in daily_tags:  #iterating though every date\n",
    "    daily_counts = Counter(daily_tags[date]) #instead of having a list of all hashtags, this makes a dictionary with counts of each hashtag\n",
    "    #print(daily_counts)\n",
    "\n",
    "    for tag in daily_counts: \n",
    "        daily_tags_counted.append({\"date\": date, \"hashtag\": tag , \"count\": daily_counts[tag]})\n",
    "        #daily_tags_counted[date][tag] = daily_counts[tag]\n",
    "\n",
    "df = pd.DataFrame.from_dict(daily_tags_counted)\n",
    "#df.to_csv('daily_hashtags_myfreecams.csv',index=False)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making halfhourly metrics output file with calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_avgs = []\n",
    "\n",
    "# next step is to iterate over array to calculate hourly metrics\n",
    "for hour in hourly_dict:  #for each hour in day calculate:\n",
    "    hourly_files_sum = np.sum(hourly_dict[hour][\"number_files\"]) #how many files collected for that halfhour interval\n",
    "    hourly_shows_avg = np.mean(hourly_dict[hour][\"perf_counts\"]) #average length of page (number of performances - the ones that are online) (all platforms)\n",
    "    hourly_offline_avg = np.mean(hourly_dict[hour][\"offline_counts\"]) #average of how many people on the list were offline (bongacams and myfreecams)\n",
    "    hourly_views_sum = sum(hourly_dict[hour][\"view_sums\"]) #sum of all viewers on the platform over all collected data for that halfhour period (chaturbate, bongacams and myfreecams)\n",
    "    hourly_views_sum_avg = hourly_views_sum / hourly_files_sum #average number of viewers on the platform (chaturbate, bongacams and myfreecams)\n",
    "    hourly_views_avg =  hourly_views_sum / sum(hourly_dict[hour][\"perf_counts\"]) #average number of viewers in a show per halfhour (chaturbate, bongacams and myfreecams)\n",
    "\n",
    "    hourly_female_avg = np.mean(hourly_dict[hour][\"female_counts\"]) #only chaturbate\n",
    "    hourly_female_percent = sum(hourly_dict[hour][\"female_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    hourly_male_avg = np.mean(hourly_dict[hour][\"male_counts\"]) #only chaturbate\n",
    "    hourly_male_percent = sum(hourly_dict[hour][\"male_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    hourly_trans_avg = np.mean(hourly_dict[hour][\"trans_counts\"]) #only chaturbate\n",
    "    hourly_trans_percent = sum(hourly_dict[hour][\"trans_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    hourly_couple_avg = np.mean(hourly_dict[hour][\"couple_counts\"]) #only chaturbate\n",
    "    hourly_couple_percent = sum(hourly_dict[hour][\"couple_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #only chaturbate\n",
    "    \n",
    "    hourly_vibrator_avg = np.mean(hourly_dict[hour][\"vibrator_counts\"]) #(bongacams and livejasmin)\n",
    "    hourly_vibrator_percent = sum(hourly_dict[hour][\"vibrator_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #(bongacams and livejasmin)\n",
    "    hourly_new_avg = np.mean(hourly_dict[hour][\"new_counts\"]) #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    hourly_new_percent = sum(hourly_dict[hour][\"new_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams, chaturbate, myfreecams, livejasmin\n",
    "    hourly_promoted_avg = np.mean(hourly_dict[hour][\"promoted_counts\"]) #bongacams, livejasmin, chaturbate\n",
    "    hourly_promoted_percent = sum(hourly_dict[hour][\"promoted_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams, livejasmin, chaturbate\n",
    "\n",
    "    hourly_private_avg = np.mean(hourly_dict[hour][\"private_counts\"]) #bongacams and myfreecams\n",
    "    hourly_private_percent = sum(hourly_dict[hour][\"private_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "    hourly_group_avg = np.mean(hourly_dict[hour][\"group_counts\"]) #bongacams and myfreecams\n",
    "    hourly_group_percent = sum(hourly_dict[hour][\"group_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100 #bongacams and myfreecams\n",
    "\n",
    "\n",
    "    #then add everything to a nice dictionary\n",
    "    hourly_avgs.append({'hour':hour, 'number_files': hourly_files_sum, 'shows_average':round(hourly_shows_avg, 2), 'offline_average':round(hourly_offline_avg, 2),\n",
    "    'viewers_sum':hourly_views_sum, 'viewers_sum_avg':round(hourly_views_sum_avg,2), 'viewers_average':round(hourly_views_avg, 2),\n",
    "    'average_vibrator':round(hourly_vibrator_avg,2), 'percentage_vibrator':round(hourly_vibrator_percent,2), 'average_new':round(hourly_new_avg,2), 'percentage_new':round(hourly_new_percent,2),\n",
    "    'average_promoted':round(hourly_promoted_avg,2), 'percentage_promoted':round(hourly_promoted_percent,2), 'average_private':round(hourly_private_avg,2), 'percentage_private':round(hourly_private_percent,2),\n",
    "    'average_group':round(hourly_group_avg,2), 'percentage_group':round(hourly_group_percent,2), 'average_females':round(hourly_female_avg,2), 'percentage_females':round(hourly_female_percent,2), \n",
    "    'average_males':round(hourly_male_avg,2), 'percentage_males':round(hourly_male_percent,2), 'average_trans':round(hourly_trans_avg,2), 'percentage_trans':round(hourly_trans_percent,2), \n",
    "    'average_couples':round(hourly_couple_avg), 'percentage_couples':round(hourly_couple_percent,2)})\n",
    "    #print(hourly_avgs)\n",
    "\n",
    "#and make a dataframe from the dictionary\n",
    "df = pd.DataFrame.from_dict(hourly_avgs)\n",
    "#df.to_csv('hourly_metrics_ebonycams.csv',index=False) #and save it as a csv file\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## -- IGNORE THIS --\n",
    "Old version \n",
    "\n",
    "Bellow: collecting metrics separately per half an hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the master dictionary for collecting hourly data\n",
    "hourly_dict = {}\n",
    "#IF HASHTAGS ARE INTERESTING PER TIME IN DAY, THEN HERE THAT SHOULD BE ADDED THE SAME WAY AS IN METRICS PER DAY\n",
    "counter = 1\n",
    "\n",
    "\n",
    "# iterate over all files to create an array of lists with all metrics for each hour in a day\n",
    "for filename in sorted(csv_files):\n",
    "\n",
    "    #print(filename)\n",
    "    fileparts = filename.split('_')\n",
    "    smaller_parts = fileparts[1].split('/')\n",
    "    platform_split = smaller_parts[2].split('2')\n",
    "    platform = platform_split[0]\n",
    "    #print(platform)\n",
    "    \n",
    "    if platform == \"myfreecams\":\n",
    "        time = fileparts[2]\n",
    "        print(time)\n",
    "    else:\n",
    "        time = fileparts[3]\n",
    "        print(time)\n",
    "   \n",
    "    timeparts = time.split('-')\n",
    "    hour = f\"0000-00-00 {timeparts[0]}:{timeparts[1]}:00\"\n",
    "    #print(hour)\n",
    "    \n",
    "    print(str(counter) + ' ' + hour + ' ' + platform)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "    if hour not in hourly_dict: #add the hour to a dictionary with keys for each hour\n",
    "        hourly_dict[hour] = {\"perf_counts\":[], \"view_sums\":[], \"show_length_sums\":[], \"female_counts\":[], \"male_counts\":[], \"trans_counts\":[], \"couple_counts\":[], \n",
    "                            \"vibrator_counts\":[], \"new_counts\":[], \"private_counts\":[], \"group_counts\":[], \"offline_counts\":[], \"promoted_counts\":[], \"number_files\":[]} \n",
    "                            #create a dictionary within each date for metrics and list for each value\n",
    "\n",
    "\n",
    "    # __________________________read CSV file and get metrics________________________________________\n",
    "    # this obviously could be done together with hourly metrics, so the files don't need to be opened twice, but for now i am keeping it this way\n",
    "    # because i already have run the metrics for days in the timeframe\n",
    "\n",
    "    df = pd.read_csv(filename) #open the csv as dataframe\n",
    "    files = 1\n",
    "    \n",
    "    all_performers_count = len(df)\n",
    "    \n",
    "    if \"offline\" in df.columns:\n",
    "        offline_count = df.offline.sum()\n",
    "        df = df[df[\"offline\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might exist (ebony), but were removed\")\n",
    "    elif \"away\" in df.columns:\n",
    "        offline_count = df.away.sum()\n",
    "        df = df[df[\"away\"] == False] #filtering out the rows that have offline performers\n",
    "        #print(\"offline performers might existe (bonga), but were removed\")\n",
    "    else:\n",
    "        offline_count = 0\n",
    "        #print(\"this plaform does not save offline performers, proceeding >>\")\n",
    "    \n",
    "    \n",
    "    perf_count = len(df) #number of shows in each csv file\n",
    "    print(f\"number of online performers:{perf_count}, number of offline performers: {offline_count}, number of all performers: {all_performers_count}\")\n",
    "    print(f\"{perf_count}?\")\n",
    "    print(all_performers_count - offline_count)\n",
    "    \n",
    "# _______________viewers___________\n",
    "\n",
    "    if \"viewers\" in df.columns:\n",
    "        df['viewers'] = df['viewers'].astype(str) #first make all viewer counts into string\n",
    "        df['viewers'] = df['viewers'].str.replace('+', '') #then remove any \"+\"\" from strings\n",
    "        df[\"viewers\"] = pd.to_numeric(df[\"viewers\"]) #then make them into integers again -- this is to fix bongacams issue of having \"99999+\" as a number of viewers\n",
    "        #df[\"viewers\"] = df[\"viewers\"].astype(int)\n",
    "        view_sum = df[\"viewers\"].sum() #sum of viewers in each csv file\n",
    "        print(f\"got sum of viewers chaturbate/bongacams: {view_sum}\")\n",
    "    elif \"room_count\" in df.columns:\n",
    "        view_sum = df[\"room_count\"].sum()\n",
    "        print(f\"got sum of viewers myfreecams: {view_sum}\")    \n",
    "    else:\n",
    "        view_sum = 0\n",
    "        print(\"no viewer numbers for this platform\")\n",
    "    \n",
    "    #try:\n",
    "    #    show_len_sum = sum(df[\"time\"]) #sum of show time in each csv file\n",
    "    #except:\n",
    "    #    show_len_sum = 0\n",
    "    #    print(\"this platform does not provide show lengths\")\n",
    "    #skipping this part because it is only on chaturbate and is not accurate, because it is not actually show length, \n",
    "    #but how long the performer has been online at the moment of scrape\n",
    "    \n",
    "# _______________gender, couples___________\n",
    "    #this is only for chaturbate:\n",
    "    if \"female\" in df.columns:    #they all go together\n",
    "        female_count = df.female.sum() #number of female performers in chaturbate files\n",
    "        male_count = df.male.sum() #number of male performers\n",
    "        trans_count = df.trans.sum() #number of trans performers\n",
    "        couple_count = df.couple.sum() #number of couples performing\n",
    "\n",
    "    else:\n",
    "        female_count = 0\n",
    "        male_count = 0\n",
    "        trans_count = 0\n",
    "        couple_count = 0\n",
    "        #print(\"this platform does not provide gender indications\")\n",
    "\n",
    "# _______________vibrator use___________\n",
    "    if \"vibrator\" in df.columns:\n",
    "        vibrator_count = df.vibrator.sum() #number of performances with smart vibrators activated \n",
    "    else:\n",
    "        vibrator_count = 0\n",
    "        #print(\"this platform does not provide vibrator indication\")\n",
    "\n",
    "# _______________new performers___________\n",
    "    if \"new\" in df.columns: \n",
    "        new_count = df.new.sum() #number of new performers \n",
    "    else:\n",
    "        new_count = 0\n",
    "        #print(\"this platform does not provide new performer indication\")\n",
    "    \n",
    "# _______________performers in private shows___________   \n",
    "    if \"private\" in df.columns:\n",
    "        private_count = df.private.sum()  #number of performers in a private show at the moment (bongacams)\n",
    "        #print(f\"got bongacams privates: {private_count}\")\n",
    "    elif \"private_show\" in df.columns:\n",
    "        private_count = df.private_show.sum() + df.true_private_show.sum() #number of performers in a private show at the moment (myfreecams)\n",
    "        #print(f\"got myfreecams privates: {private_count}\")\n",
    "    else:\n",
    "        private_count = 0\n",
    "        #print(\"this platform does not provide private show indication\")\n",
    "    \n",
    "# _______________promoted performers___________    \n",
    "\n",
    "    if \"promoted\" in df.columns:\n",
    "        promoted_count = df.promoted.sum()\n",
    "        #print(f\"got promoted performers (livejasmin/chaturbate): {promoted_count}\")\n",
    "    elif \"lifted_up_webcam_model\" in df.columns:\n",
    "        promoted_count = df.lifted_up_webcam_model.sum()\n",
    "        #print(f\"got promoted performers (bongacams): {promoted_count}\")\n",
    "    else:\n",
    "        promoted_count = 0\n",
    "        #print(\"this platform does not provide promoted performer indication\")\n",
    "\n",
    "# _______________performers in group shows___________   \n",
    "    if \"group\" in df.columns:\n",
    "        group_count = df.group.sum() #bonga\n",
    "        #print(f\"got performers in group shows (bongacams): {group_count}\")\n",
    "    elif \"group_show\" in df.columns:\n",
    "        group_count = df.group_show.sum() #myfreecams\n",
    "        #print(f\"got performers in group shows (myfreecams): {group_count}\")\n",
    "    else:\n",
    "        group_count = 0\n",
    "        #print(\"this platform does not provide group show indication\")\n",
    "\n",
    "\n",
    "   # __________________________put metrics in a dictionary________________________________________\n",
    "    # add all the new collected values in the nested dictionary\n",
    "    hourly_dict[hour][\"perf_counts\"].append(perf_count)\n",
    "    hourly_dict[hour][\"view_sums\"].append(view_sum)\n",
    "    hourly_dict[hour][\"female_counts\"].append(female_count)\n",
    "    hourly_dict[hour][\"male_counts\"].append(male_count)\n",
    "    hourly_dict[hour][\"trans_counts\"].append(trans_count)\n",
    "    hourly_dict[hour][\"couple_counts\"].append(couple_count)\n",
    "    hourly_dict[hour][\"vibrator_counts\"].append(vibrator_count)\n",
    "    hourly_dict[hour][\"new_counts\"].append(new_count)\n",
    "    hourly_dict[hour][\"private_counts\"].append(private_count)\n",
    "    hourly_dict[hour][\"offline_counts\"].append(offline_count)\n",
    "    hourly_dict[hour][\"promoted_counts\"].append(promoted_count)\n",
    "    hourly_dict[hour][\"group_counts\"].append(group_count)\n",
    "    hourly_dict[hour][\"number_files\"].append(files)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
