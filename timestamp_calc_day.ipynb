{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics per day\n",
    "- this is code for reading multiple frontpage files and calculating metrics per timestamp (here-daily)\n",
    "- code is based on the example from \"basic_file_read\" by Bernhard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below choose which directory to work with (all files or test files)\n",
    "path = 'homepage_csvs/test/'\n",
    "#path = 'homepage_csvs/chaturbate/'\n",
    "\n",
    "# get all filenames from the directory\n",
    "csv_files = glob.glob(path + '*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2021-11-09\n",
      "1 2021-11-09\n",
      "2 2021-11-09\n",
      "3 2021-11-09\n",
      "4 2021-11-09\n",
      "5 2021-11-09\n",
      "6 2021-11-09\n",
      "7 2021-11-09\n",
      "8 2021-11-09\n",
      "9 2021-11-09\n",
      "10 2021-11-09\n",
      "11 2021-11-09\n",
      "12 2021-11-09\n",
      "13 2021-11-09\n",
      "14 2021-11-09\n",
      "15 2021-11-09\n",
      "16 2021-11-09\n",
      "17 2021-11-09\n",
      "18 2021-11-09\n",
      "19 2021-11-09\n",
      "20 2021-11-09\n",
      "21 2021-11-09\n",
      "22 2021-11-09\n",
      "23 2021-11-09\n",
      "24 2021-11-09\n",
      "25 2021-11-09\n",
      "26 2021-11-09\n",
      "27 2021-11-09\n",
      "28 2021-11-09\n",
      "29 2021-11-09\n",
      "30 2021-11-09\n",
      "31 2021-11-09\n",
      "32 2021-11-09\n",
      "33 2021-11-09\n",
      "34 2021-11-09\n",
      "35 2021-11-09\n",
      "36 2021-11-09\n",
      "37 2021-11-09\n",
      "38 2021-11-09\n",
      "39 2021-11-09\n",
      "40 2021-11-09\n",
      "41 2021-11-09\n",
      "42 2021-11-09\n",
      "43 2021-11-09\n",
      "44 2021-11-09\n",
      "45 2021-11-09\n",
      "46 2021-11-09\n",
      "47 2021-11-11\n",
      "48 2021-11-11\n",
      "49 2021-11-11\n",
      "50 2021-11-11\n",
      "51 2021-11-11\n",
      "52 2021-11-12\n",
      "53 2021-11-12\n",
      "54 2021-11-12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "daily_dict = {} #create an empty dictionary to store all metrics for daily calculations\n",
    "daily_tags = {} #create an empty dictionary to store a list of all hashtags per day\n",
    "counter = 0\n",
    "\n",
    "# iterate over all files to create an array of lists with all metrics for each day\n",
    "for filename in sorted(csv_files):\n",
    "    \n",
    "    # extract date from filename\n",
    "    fileparts = filename.split('_')\n",
    "    date = fileparts[2]\n",
    "\n",
    "    if date not in daily_dict: #add the date to a dictionary with keys for each date\n",
    "        daily_dict[date] = {\"perf_counts\":[], \"view_sums\":[], \"show_length_sums\":[], \n",
    "                            \"female_counts\":[], \"male_counts\":[], \"trans_counts\":[], \"couple_counts\":[]} \n",
    "                            #create a dictionary within each date for metrics and list for each value\n",
    "        daily_tags[date] = []\n",
    "\n",
    "    # read CSV file and get metrics\n",
    "    df = pd.read_csv(filename)\n",
    "    perf_count = len(df) #number of shows in each csv file\n",
    "    view_sum = sum(df[\"viewers\"]) #sum of viewers in each csv file\n",
    "    show_len_sum = sum(df[\"time\"]) #sum of show time in each csv file\n",
    "    female_count = df.female.sum() #number of female performers in each csv file\n",
    "    male_count = df.male.sum() #number of male performers\n",
    "    trans_count = df.trans.sum() #number of trans performers\n",
    "    couple_count = df.couple.sum() #number of couples performing\n",
    "    hashtags_list = df[\"tags\"].tolist() #makes a list of all the hashtags used that day\n",
    "\n",
    "    #below, takes the list of hashtags collected and flattens it \n",
    "    hashtags = []\n",
    "    for object in hashtags_list:\n",
    "        #print(object)\n",
    "        if type(object) is str:\n",
    "            #print(type(object))\n",
    "            object = object.split(\",\")\n",
    "            for word in object:\n",
    "                hashtags.append(word)\n",
    "        else:\n",
    "            #print(type(object))\n",
    "            hashtags.append(object)\n",
    "\n",
    "    #print(hashtags)\n",
    "\n",
    "    # add all the new collected values in the nested dictionary\n",
    "    daily_dict[date][\"perf_counts\"].append(perf_count)\n",
    "    daily_dict[date][\"view_sums\"].append(view_sum)\n",
    "    daily_dict[date][\"show_length_sums\"].append(show_len_sum)\n",
    "    daily_dict[date][\"female_counts\"].append(female_count)\n",
    "    daily_dict[date][\"male_counts\"].append(male_count)\n",
    "    daily_dict[date][\"trans_counts\"].append(trans_count)\n",
    "    daily_dict[date][\"couple_counts\"].append(couple_count)\n",
    "\n",
    "    #add the collected hashtags in their own dictionary\n",
    "    daily_tags[date]+=hashtags\n",
    "\n",
    "\n",
    "\n",
    "    print(str(counter) + ' ' + date)\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "#print(daily_dict)\n",
    "#print(daily_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>shows_average</th>\n",
       "      <th>viewers_average</th>\n",
       "      <th>show_length_average</th>\n",
       "      <th>average_females</th>\n",
       "      <th>percentage_females</th>\n",
       "      <th>average_males</th>\n",
       "      <th>percentage_males</th>\n",
       "      <th>average_trans</th>\n",
       "      <th>percentage_trans</th>\n",
       "      <th>average_couples</th>\n",
       "      <th>percentage_couples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>6857.77</td>\n",
       "      <td>48.56</td>\n",
       "      <td>150.35</td>\n",
       "      <td>4798.19</td>\n",
       "      <td>69.97</td>\n",
       "      <td>1224.04</td>\n",
       "      <td>17.85</td>\n",
       "      <td>507.04</td>\n",
       "      <td>7.39</td>\n",
       "      <td>328</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>5704.60</td>\n",
       "      <td>50.23</td>\n",
       "      <td>155.00</td>\n",
       "      <td>4011.60</td>\n",
       "      <td>70.32</td>\n",
       "      <td>985.40</td>\n",
       "      <td>17.27</td>\n",
       "      <td>432.60</td>\n",
       "      <td>7.58</td>\n",
       "      <td>275</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>6509.00</td>\n",
       "      <td>45.25</td>\n",
       "      <td>172.28</td>\n",
       "      <td>4594.00</td>\n",
       "      <td>70.58</td>\n",
       "      <td>1082.33</td>\n",
       "      <td>16.63</td>\n",
       "      <td>546.33</td>\n",
       "      <td>8.39</td>\n",
       "      <td>286</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  shows_average  viewers_average  show_length_average  \\\n",
       "0  2021-11-09        6857.77            48.56               150.35   \n",
       "1  2021-11-11        5704.60            50.23               155.00   \n",
       "2  2021-11-12        6509.00            45.25               172.28   \n",
       "\n",
       "   average_females  percentage_females  average_males  percentage_males  \\\n",
       "0          4798.19               69.97        1224.04             17.85   \n",
       "1          4011.60               70.32         985.40             17.27   \n",
       "2          4594.00               70.58        1082.33             16.63   \n",
       "\n",
       "   average_trans  percentage_trans  average_couples  percentage_couples  \n",
       "0         507.04              7.39              328                4.79  \n",
       "1         432.60              7.58              275                4.82  \n",
       "2         546.33              8.39              286                4.40  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_avgs = []\n",
    "\n",
    "# next step is to iterate over array to calculate daily averages\n",
    "for date in daily_dict:\n",
    "    #for each date calculate\n",
    "    daily_shows_avg = np.mean(daily_dict[date][\"perf_counts\"]) #average length of page (number of performances)\n",
    "    daily_views_avg = sum(daily_dict[date][\"view_sums\"]) / sum(daily_dict[date][\"perf_counts\"]) #average number of viewers per day\n",
    "    daily_length_avg = sum(daily_dict[date][\"show_length_sums\"]) / sum(daily_dict[date][\"perf_counts\"]) #average length of show per day\n",
    "    daily_female_avg = np.mean(daily_dict[date][\"female_counts\"])\n",
    "    daily_female_percent = sum(daily_dict[date][\"female_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100\n",
    "    daily_male_avg = np.mean(daily_dict[date][\"male_counts\"])\n",
    "    daily_male_percent = sum(daily_dict[date][\"male_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100\n",
    "    daily_trans_avg = np.mean(daily_dict[date][\"trans_counts\"])\n",
    "    daily_trans_percent = sum(daily_dict[date][\"trans_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100\n",
    "    daily_couple_avg = np.mean(daily_dict[date][\"couple_counts\"])\n",
    "    daily_couple_percent = sum(daily_dict[date][\"couple_counts\"]) / sum(daily_dict[date][\"perf_counts\"]) * 100\n",
    "\n",
    "\n",
    "    #then add everything to a nice dictionary\n",
    "    daily_avgs.append({'date':date,'shows_average':round(daily_shows_avg, 2), 'viewers_average':round(daily_views_avg, 2), 'show_length_average':round(daily_length_avg, 2),\n",
    "                        'average_females':round(daily_female_avg,2), 'percentage_females':round(daily_female_percent,2), 'average_males':round(daily_male_avg,2), 'percentage_males':round(daily_male_percent,2),\n",
    "                        'average_trans':round(daily_trans_avg,2), 'percentage_trans':round(daily_trans_percent,2), 'average_couples':round(daily_couple_avg), 'percentage_couples':round(daily_couple_percent,2)})\n",
    "    #print(daily_avgs)\n",
    "\n",
    "#and make a dataframe from the dictionary\n",
    "df = pd.DataFrame.from_dict(daily_avgs)\n",
    "df.to_csv('daily_averages.csv',index=False) #and save it as a csv file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>#lovense</td>\n",
       "      <td>41098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>#tattoo</td>\n",
       "      <td>3633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>#ink</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>#latina</td>\n",
       "      <td>47531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>#fountainsquirt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>#bwc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>#teasing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>#africa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>#hairybush</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5421 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date           hashtag  count\n",
       "0     2021-11-09               NaN  50177\n",
       "1     2021-11-09          #lovense  41098\n",
       "2     2021-11-09           #tattoo   3633\n",
       "3     2021-11-09              #ink     28\n",
       "4     2021-11-09           #latina  47531\n",
       "...          ...               ...    ...\n",
       "5416  2021-11-12   #fountainsquirt      1\n",
       "5417  2021-11-12              #bwc      1\n",
       "5418  2021-11-12          #teasing      1\n",
       "5419  2021-11-12           #africa      1\n",
       "5420  2021-11-12        #hairybush      1\n",
       "\n",
       "[5421 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here i make a file with the counted hashtags over time\n",
    "# FUTURE: not include all hashtags, but only those that are counted above a threshold?\n",
    "\n",
    "daily_tags_counted = []\n",
    "\n",
    "for date in daily_tags:  #iterating though every date\n",
    "    daily_counts = Counter(daily_tags[date]) #instead of having a list of all hashtags, this makes a dictionary with counts of each hashtag\n",
    "    #print(daily_counts)\n",
    "\n",
    "    for tag in daily_counts: \n",
    "        daily_tags_counted.append({\"date\": date, \"hashtag\": tag , \"count\": daily_counts[tag]})\n",
    "        #daily_tags_counted[date][tag] = daily_counts[tag]\n",
    "\n",
    "df = pd.DataFrame.from_dict(daily_tags_counted)\n",
    "df.to_csv('daily_hashtags.csv',index=False)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics per hour in day\n",
    "- next, we use a similar approach to look at metrics per hour and analyze performer work \"rhythms\" during different times of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 00\n",
      "1 00\n",
      "2 01\n",
      "3 01\n",
      "4 02\n",
      "5 02\n",
      "6 03\n",
      "7 03\n",
      "8 04\n",
      "9 04\n",
      "10 05\n",
      "11 05\n",
      "12 06\n",
      "13 06\n",
      "14 07\n",
      "15 07\n",
      "16 08\n",
      "17 08\n",
      "18 09\n",
      "19 09\n",
      "20 10\n",
      "21 10\n",
      "22 11\n",
      "23 11\n",
      "24 12\n",
      "25 12\n",
      "26 13\n",
      "27 13\n",
      "28 14\n",
      "29 14\n",
      "30 15\n",
      "31 15\n",
      "32 16\n",
      "33 16\n",
      "34 17\n",
      "35 17\n",
      "36 18\n",
      "37 18\n",
      "38 19\n",
      "39 19\n",
      "40 20\n",
      "41 20\n",
      "42 21\n",
      "43 22\n",
      "44 22\n",
      "45 23\n",
      "46 23\n",
      "47 10\n",
      "48 11\n",
      "49 12\n",
      "50 13\n",
      "51 13\n",
      "52 08\n",
      "53 09\n",
      "54 10\n"
     ]
    }
   ],
   "source": [
    "#make the master dictionary for collecting hourly data\n",
    "hourly_dict = {}\n",
    "#IF HASHTAGS ARE INTERESTING PER TIME IN DAY, THEN HERE THAT SHOULD BE ADDED THE SAME WAY AS IN METRICS PER DAY\n",
    "counter = 0\n",
    "\n",
    "for filename in sorted(csv_files):\n",
    "\n",
    "    # extract hour from filename\n",
    "    fileparts = filename.split('_')\n",
    "    time = fileparts[3]\n",
    "    timeparts = time.split('-')\n",
    "    hour = timeparts[0]\n",
    "\n",
    "    if hour not in hourly_dict:\n",
    "       hourly_dict[hour] = {\"perf_counts\":[], \"view_sums\":[], \"show_length_sums\":[],\n",
    "                            \"female_counts\":[], \"male_counts\":[], \"trans_counts\":[], \"couple_counts\":[]}\n",
    "    \n",
    "    # read CSV file and collect needed metrics\n",
    "    df = pd.read_csv(filename)\n",
    "    perf_count = len(df) #number of shows in each csv file\n",
    "    view_sum = sum(df[\"viewers\"]) #sum of viewers in each csv file\n",
    "    show_len_sum = sum(df[\"time\"]) #sum of show length in each csv file\n",
    "    female_count = df.female.sum() #number of female performers in each csv file\n",
    "    male_count = df.male.sum() #number of male performers\n",
    "    trans_count = df.trans.sum() #number of trans performers\n",
    "    couple_count = df.couple.sum() #number of couples performing\n",
    "\n",
    "\n",
    "    hourly_dict[hour][\"perf_counts\"].append(perf_count)\n",
    "    hourly_dict[hour][\"view_sums\"].append(view_sum)\n",
    "    hourly_dict[hour][\"show_length_sums\"].append(show_len_sum)\n",
    "    hourly_dict[hour][\"female_counts\"].append(female_count)\n",
    "    hourly_dict[hour][\"male_counts\"].append(male_count)\n",
    "    hourly_dict[hour][\"trans_counts\"].append(trans_count)\n",
    "    hourly_dict[hour][\"couple_counts\"].append(couple_count)\n",
    "\n",
    "\n",
    "    print(str(counter) + ' ' + hour)\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "#print(hourly_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shows_average</th>\n",
       "      <th>viewers_average</th>\n",
       "      <th>show_length_average</th>\n",
       "      <th>average_females</th>\n",
       "      <th>percentage_females</th>\n",
       "      <th>average_males</th>\n",
       "      <th>percentage_males</th>\n",
       "      <th>average_trans</th>\n",
       "      <th>percentage_trans</th>\n",
       "      <th>average_couples</th>\n",
       "      <th>percentage_couples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7822.00</td>\n",
       "      <td>50.98</td>\n",
       "      <td>158.89</td>\n",
       "      <td>5384.00</td>\n",
       "      <td>68.83</td>\n",
       "      <td>1449.50</td>\n",
       "      <td>18.53</td>\n",
       "      <td>581.50</td>\n",
       "      <td>7.43</td>\n",
       "      <td>407</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7422.50</td>\n",
       "      <td>47.87</td>\n",
       "      <td>177.94</td>\n",
       "      <td>5126.00</td>\n",
       "      <td>69.06</td>\n",
       "      <td>1366.50</td>\n",
       "      <td>18.41</td>\n",
       "      <td>551.00</td>\n",
       "      <td>7.42</td>\n",
       "      <td>379</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6908.00</td>\n",
       "      <td>46.87</td>\n",
       "      <td>177.33</td>\n",
       "      <td>4779.50</td>\n",
       "      <td>69.19</td>\n",
       "      <td>1259.00</td>\n",
       "      <td>18.23</td>\n",
       "      <td>545.00</td>\n",
       "      <td>7.89</td>\n",
       "      <td>324</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6358.50</td>\n",
       "      <td>47.26</td>\n",
       "      <td>156.66</td>\n",
       "      <td>4261.00</td>\n",
       "      <td>67.01</td>\n",
       "      <td>1255.50</td>\n",
       "      <td>19.75</td>\n",
       "      <td>514.50</td>\n",
       "      <td>8.09</td>\n",
       "      <td>328</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6391.00</td>\n",
       "      <td>46.83</td>\n",
       "      <td>133.68</td>\n",
       "      <td>4242.00</td>\n",
       "      <td>66.37</td>\n",
       "      <td>1305.50</td>\n",
       "      <td>20.43</td>\n",
       "      <td>493.00</td>\n",
       "      <td>7.71</td>\n",
       "      <td>350</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6661.00</td>\n",
       "      <td>46.11</td>\n",
       "      <td>125.54</td>\n",
       "      <td>4471.00</td>\n",
       "      <td>67.12</td>\n",
       "      <td>1284.50</td>\n",
       "      <td>19.28</td>\n",
       "      <td>548.00</td>\n",
       "      <td>8.23</td>\n",
       "      <td>358</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6400.00</td>\n",
       "      <td>47.53</td>\n",
       "      <td>132.04</td>\n",
       "      <td>4273.00</td>\n",
       "      <td>66.77</td>\n",
       "      <td>1279.00</td>\n",
       "      <td>19.98</td>\n",
       "      <td>525.50</td>\n",
       "      <td>8.21</td>\n",
       "      <td>322</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6020.50</td>\n",
       "      <td>49.02</td>\n",
       "      <td>145.31</td>\n",
       "      <td>4081.00</td>\n",
       "      <td>67.79</td>\n",
       "      <td>1125.50</td>\n",
       "      <td>18.69</td>\n",
       "      <td>527.00</td>\n",
       "      <td>8.75</td>\n",
       "      <td>287</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6208.33</td>\n",
       "      <td>49.18</td>\n",
       "      <td>158.11</td>\n",
       "      <td>4318.67</td>\n",
       "      <td>69.56</td>\n",
       "      <td>1071.33</td>\n",
       "      <td>17.26</td>\n",
       "      <td>527.33</td>\n",
       "      <td>8.49</td>\n",
       "      <td>291</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6024.33</td>\n",
       "      <td>46.58</td>\n",
       "      <td>169.86</td>\n",
       "      <td>4227.00</td>\n",
       "      <td>70.17</td>\n",
       "      <td>1029.00</td>\n",
       "      <td>17.08</td>\n",
       "      <td>490.00</td>\n",
       "      <td>8.13</td>\n",
       "      <td>278</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5828.75</td>\n",
       "      <td>47.11</td>\n",
       "      <td>182.18</td>\n",
       "      <td>4090.75</td>\n",
       "      <td>70.18</td>\n",
       "      <td>1003.00</td>\n",
       "      <td>17.21</td>\n",
       "      <td>471.50</td>\n",
       "      <td>8.09</td>\n",
       "      <td>264</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4946.00</td>\n",
       "      <td>55.36</td>\n",
       "      <td>185.50</td>\n",
       "      <td>3422.67</td>\n",
       "      <td>69.20</td>\n",
       "      <td>913.33</td>\n",
       "      <td>18.47</td>\n",
       "      <td>377.00</td>\n",
       "      <td>7.62</td>\n",
       "      <td>233</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4711.00</td>\n",
       "      <td>60.56</td>\n",
       "      <td>154.27</td>\n",
       "      <td>3259.67</td>\n",
       "      <td>69.19</td>\n",
       "      <td>856.33</td>\n",
       "      <td>18.18</td>\n",
       "      <td>366.00</td>\n",
       "      <td>7.77</td>\n",
       "      <td>229</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5873.50</td>\n",
       "      <td>50.83</td>\n",
       "      <td>123.46</td>\n",
       "      <td>4203.50</td>\n",
       "      <td>71.57</td>\n",
       "      <td>973.25</td>\n",
       "      <td>16.57</td>\n",
       "      <td>425.50</td>\n",
       "      <td>7.24</td>\n",
       "      <td>271</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7021.00</td>\n",
       "      <td>46.67</td>\n",
       "      <td>106.93</td>\n",
       "      <td>5085.50</td>\n",
       "      <td>72.43</td>\n",
       "      <td>1161.00</td>\n",
       "      <td>16.54</td>\n",
       "      <td>460.00</td>\n",
       "      <td>6.55</td>\n",
       "      <td>314</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7876.00</td>\n",
       "      <td>46.12</td>\n",
       "      <td>114.52</td>\n",
       "      <td>5748.00</td>\n",
       "      <td>72.98</td>\n",
       "      <td>1257.50</td>\n",
       "      <td>15.97</td>\n",
       "      <td>529.00</td>\n",
       "      <td>6.72</td>\n",
       "      <td>342</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8236.00</td>\n",
       "      <td>45.22</td>\n",
       "      <td>138.30</td>\n",
       "      <td>5968.50</td>\n",
       "      <td>72.47</td>\n",
       "      <td>1342.50</td>\n",
       "      <td>16.30</td>\n",
       "      <td>553.50</td>\n",
       "      <td>6.72</td>\n",
       "      <td>372</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8393.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>165.61</td>\n",
       "      <td>6094.00</td>\n",
       "      <td>72.61</td>\n",
       "      <td>1361.00</td>\n",
       "      <td>16.22</td>\n",
       "      <td>554.00</td>\n",
       "      <td>6.60</td>\n",
       "      <td>384</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8129.00</td>\n",
       "      <td>47.08</td>\n",
       "      <td>187.15</td>\n",
       "      <td>5900.00</td>\n",
       "      <td>72.58</td>\n",
       "      <td>1346.50</td>\n",
       "      <td>16.56</td>\n",
       "      <td>530.50</td>\n",
       "      <td>6.53</td>\n",
       "      <td>352</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7497.00</td>\n",
       "      <td>50.93</td>\n",
       "      <td>190.04</td>\n",
       "      <td>5345.50</td>\n",
       "      <td>71.30</td>\n",
       "      <td>1303.50</td>\n",
       "      <td>17.39</td>\n",
       "      <td>490.00</td>\n",
       "      <td>6.54</td>\n",
       "      <td>358</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6841.00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>147.07</td>\n",
       "      <td>4709.00</td>\n",
       "      <td>68.83</td>\n",
       "      <td>1282.50</td>\n",
       "      <td>18.75</td>\n",
       "      <td>491.00</td>\n",
       "      <td>7.18</td>\n",
       "      <td>358</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7651.00</td>\n",
       "      <td>46.88</td>\n",
       "      <td>117.30</td>\n",
       "      <td>5400.00</td>\n",
       "      <td>70.58</td>\n",
       "      <td>1371.00</td>\n",
       "      <td>17.92</td>\n",
       "      <td>534.00</td>\n",
       "      <td>6.98</td>\n",
       "      <td>346</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8641.00</td>\n",
       "      <td>44.93</td>\n",
       "      <td>126.26</td>\n",
       "      <td>6105.50</td>\n",
       "      <td>70.66</td>\n",
       "      <td>1518.00</td>\n",
       "      <td>17.57</td>\n",
       "      <td>618.50</td>\n",
       "      <td>7.16</td>\n",
       "      <td>399</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8500.50</td>\n",
       "      <td>48.17</td>\n",
       "      <td>141.91</td>\n",
       "      <td>5973.50</td>\n",
       "      <td>70.27</td>\n",
       "      <td>1511.50</td>\n",
       "      <td>17.78</td>\n",
       "      <td>603.00</td>\n",
       "      <td>7.09</td>\n",
       "      <td>412</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shows_average  viewers_average  show_length_average  average_females  \\\n",
       "0         7822.00            50.98               158.89          5384.00   \n",
       "1         7422.50            47.87               177.94          5126.00   \n",
       "2         6908.00            46.87               177.33          4779.50   \n",
       "3         6358.50            47.26               156.66          4261.00   \n",
       "4         6391.00            46.83               133.68          4242.00   \n",
       "5         6661.00            46.11               125.54          4471.00   \n",
       "6         6400.00            47.53               132.04          4273.00   \n",
       "7         6020.50            49.02               145.31          4081.00   \n",
       "8         6208.33            49.18               158.11          4318.67   \n",
       "9         6024.33            46.58               169.86          4227.00   \n",
       "10        5828.75            47.11               182.18          4090.75   \n",
       "11        4946.00            55.36               185.50          3422.67   \n",
       "12        4711.00            60.56               154.27          3259.67   \n",
       "13        5873.50            50.83               123.46          4203.50   \n",
       "14        7021.00            46.67               106.93          5085.50   \n",
       "15        7876.00            46.12               114.52          5748.00   \n",
       "16        8236.00            45.22               138.30          5968.50   \n",
       "17        8393.00            45.97               165.61          6094.00   \n",
       "18        8129.00            47.08               187.15          5900.00   \n",
       "19        7497.00            50.93               190.04          5345.50   \n",
       "20        6841.00            50.57               147.07          4709.00   \n",
       "21        7651.00            46.88               117.30          5400.00   \n",
       "22        8641.00            44.93               126.26          6105.50   \n",
       "23        8500.50            48.17               141.91          5973.50   \n",
       "\n",
       "    percentage_females  average_males  percentage_males  average_trans  \\\n",
       "0                68.83        1449.50             18.53         581.50   \n",
       "1                69.06        1366.50             18.41         551.00   \n",
       "2                69.19        1259.00             18.23         545.00   \n",
       "3                67.01        1255.50             19.75         514.50   \n",
       "4                66.37        1305.50             20.43         493.00   \n",
       "5                67.12        1284.50             19.28         548.00   \n",
       "6                66.77        1279.00             19.98         525.50   \n",
       "7                67.79        1125.50             18.69         527.00   \n",
       "8                69.56        1071.33             17.26         527.33   \n",
       "9                70.17        1029.00             17.08         490.00   \n",
       "10               70.18        1003.00             17.21         471.50   \n",
       "11               69.20         913.33             18.47         377.00   \n",
       "12               69.19         856.33             18.18         366.00   \n",
       "13               71.57         973.25             16.57         425.50   \n",
       "14               72.43        1161.00             16.54         460.00   \n",
       "15               72.98        1257.50             15.97         529.00   \n",
       "16               72.47        1342.50             16.30         553.50   \n",
       "17               72.61        1361.00             16.22         554.00   \n",
       "18               72.58        1346.50             16.56         530.50   \n",
       "19               71.30        1303.50             17.39         490.00   \n",
       "20               68.83        1282.50             18.75         491.00   \n",
       "21               70.58        1371.00             17.92         534.00   \n",
       "22               70.66        1518.00             17.57         618.50   \n",
       "23               70.27        1511.50             17.78         603.00   \n",
       "\n",
       "    percentage_trans  average_couples  percentage_couples  \n",
       "0               7.43              407                5.20  \n",
       "1               7.42              379                5.11  \n",
       "2               7.89              324                4.70  \n",
       "3               8.09              328                5.15  \n",
       "4               7.71              350                5.48  \n",
       "5               8.23              358                5.37  \n",
       "6               8.21              322                5.04  \n",
       "7               8.75              287                4.77  \n",
       "8               8.49              291                4.69  \n",
       "9               8.13              278                4.62  \n",
       "10              8.09              264                4.52  \n",
       "11              7.62              233                4.71  \n",
       "12              7.77              229                4.86  \n",
       "13              7.24              271                4.62  \n",
       "14              6.55              314                4.48  \n",
       "15              6.72              342                4.34  \n",
       "16              6.72              372                4.51  \n",
       "17              6.60              384                4.58  \n",
       "18              6.53              352                4.33  \n",
       "19              6.54              358                4.78  \n",
       "20              7.18              358                5.24  \n",
       "21              6.98              346                4.52  \n",
       "22              7.16              399                4.62  \n",
       "23              7.09              412                4.85  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_avgs = []\n",
    "\n",
    "# next step is to iterate over array to calculate hourly metrics\n",
    "for hour in hourly_dict:\n",
    "    \n",
    "    hourly_shows_avg = np.mean(hourly_dict[hour][\"perf_counts\"])\n",
    "    hourly_views_avg = sum(hourly_dict[hour][\"view_sums\"]) / sum(hourly_dict[hour][\"perf_counts\"])\n",
    "    hourly_length_avg = sum(hourly_dict[hour][\"show_length_sums\"]) / sum(hourly_dict[hour][\"perf_counts\"])\n",
    "    hourly_female_avg = np.mean(hourly_dict[hour][\"female_counts\"])\n",
    "    hourly_female_percent = sum(hourly_dict[hour][\"female_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100\n",
    "    hourly_male_avg = np.mean(hourly_dict[hour][\"male_counts\"])\n",
    "    hourly_male_percent = sum(hourly_dict[hour][\"male_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100\n",
    "    hourly_trans_avg = np.mean(hourly_dict[hour][\"trans_counts\"])\n",
    "    hourly_trans_percent = sum(hourly_dict[hour][\"trans_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100\n",
    "    hourly_couple_avg = np.mean(hourly_dict[hour][\"couple_counts\"])\n",
    "    hourly_couple_percent = sum(hourly_dict[hour][\"couple_counts\"]) / sum(hourly_dict[hour][\"perf_counts\"]) * 100\n",
    "    \n",
    "    hourly_avgs.append({'shows_average':round(hourly_shows_avg, 2), 'viewers_average':round(hourly_views_avg, 2), 'show_length_average':round(hourly_length_avg, 2),\n",
    "                        'average_females':round(hourly_female_avg,2), 'percentage_females':round(hourly_female_percent,2), 'average_males':round(hourly_male_avg,2), 'percentage_males':round(hourly_male_percent,2),\n",
    "                        'average_trans':round(hourly_trans_avg,2), 'percentage_trans':round(hourly_trans_percent,2), 'average_couples':round(hourly_couple_avg), 'percentage_couples':round(hourly_couple_percent,2)})\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(hourly_avgs)\n",
    "df.to_csv('hourly_averages.csv',index=False)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
